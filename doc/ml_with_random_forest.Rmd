---
title: "Machine Learning with Random Forest Models and the Tidymodels"
author: "Keith Jennings"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Why tidymodels?

Much like how the tidyverse is a group of packages for exploring, modifying, and plotting data, tidymodels provides a unified framework for statistical modeling in R. Its function-based approach allows for intuitive model set up while also letting the user make any necessary edits without changing the entire script.

## Why random forest models?

Random forest is a machine learning approach where the models learn patterns from the data to make outcome predictions. It is a form of supervised regression that can be easily run numerous times. 

Assumptions + simplicity.

## Model setup

### Packages and data
A key part to any machine learning effort is the proper set up, training, and validation of the included models. tidymodels makes this process straightforward and reproducible. Conveniently, many of the same bits of code can be used, even when the model engine changes.

First, let's load the packages we need:

```{r message = FALSE}
library(tidyverse)
library(tidymodels)
library(cowplot); theme_set(theme_cowplot()) # I like the cowplot because it makes plot pretty
```

Next, we'll need to load some data:

```{r}
df <- readRDS("doc/data/thermal_sensitivity.RDS")
```

Look at the data

### Prep the data
The first thing you need to do is split the data into *training* and *testing* sets. We'll use the former to optimize the random forest models and the latter to independently test their efficacy. Here, we'll use functions from the `rsample` package within `tidymodels`.

```{r}

```

## What if I don't have enough data?

Most machine learning methods perform best when run using large datasets. Random forest, although its simple learning algorithm lends itself well to smaller datasets, is no exception. For some of our drought impact data, we may be limited to an extremely small set of outcomes. Annual skier visits in Colorado, for example, is a time series of just 23 values. Thus, a simpler approach (i.e., ordinary least squares regression) is likely advisable.



## Acknowledgments
This was adapted from the following excellent articles:
-<https://juliasilge.com/blog/intro-tidymodels/>
-<https://www.brodrigues.co/blog/2018-11-25-tidy_cv/>
-<https://hansjoerg.me/2020/02/09/tidymodels-for-machine-learning/#tuning-model-parameters-tune-and-dials>




```{r cars}
summary(cars)
# Compute new variable
cars <- cars %>% 
  mutate(speed_dist = speed / dist)
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r}
ggplot(cars, aes(dist, speed)) + geom_point()
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
